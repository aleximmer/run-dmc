{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two step classification benchmark\n",
    "The purpose of this notebook consists in benchmarking two step classification against one step classification. Advantage of a two step approach is that most classifiers (especially SVM) have significantly shorter training times. Thus it should be evaluated how precision behaves in both approaches and the best classifier for predicting the final return quantity should be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import process as p\n",
    "import dmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = p.processed_data()\n",
    "for c in [col for col in df.columns if 'Prob' in col]:\n",
    "    df = df.drop(c, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method for running all classifiers except for neural network and return precision for each and cost for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_return_quantity_direct(df, tr_size, te_size):\n",
    "    results = []\n",
    "    X, Y = dmc.transformation.transform(df, scaler=dmc.normalization.scale_features,\n",
    "                                        binary_target=False)\n",
    "    train = X[:tr_size], Y[:tr_size]\n",
    "    test = X[tr_size:tr_size + te_size], Y[tr_size:tr_size + te_size]\n",
    "    for classifier in p.basic[:-1]:\n",
    "        clf = classifier(train[0], train[1])\n",
    "        res = clf(test[0])\n",
    "        precision = dmc.evaluation.precision(res, test[1])\n",
    "        cost = dmc.evaluation.dmc_cost(res, test[1])\n",
    "        results.append((precision, cost))\n",
    "    return np.array([r[0] for r in results]), np.array([r[1] for r in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method for running all classifiers except for neural network and return precision and cost for each but using the classifier twice. The chained fashion resembles classifying first if a row has a return and then predicting the exact label representing return Quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_return_quantity_twostep(df, tr_size, te_size):\n",
    "    results = []\n",
    "    X, Y = dmc.transformation.transform(df, scaler=dmc.normalization.scale_features,\n",
    "                                        binary_target=True)\n",
    "    Y_fin = dmc.transformation.transform_target_vector(df, binary=False)\n",
    "    train = X[:tr_size], Y[:tr_size]\n",
    "    test = X[tr_size:tr_size + te_size], Y[tr_size:tr_size + te_size]\n",
    "    for classifier in p.basic[:-1]:\n",
    "        clf = classifier(train[0], train[1])\n",
    "        res = clf(test[0])\n",
    "        Y_csr, res_csr = csr_matrix(Y).T, csr_matrix(res).T\n",
    "        train_fin = hstack([train[0], Y_csr[:tr_size]]), Y_fin[:tr_size]\n",
    "        test_fin = hstack([test[0], res_csr]), Y_fin[tr_size:tr_size + te_size]\n",
    "        clf_fin = classifier(train_fin[0], train_fin[1])\n",
    "        res_fin = clf_fin(test_fin[0])\n",
    "        precision = dmc.evaluation.precision(res_fin, test_fin[1])\n",
    "        cost = dmc.evaluation.dmc_cost(res_fin, test_fin[1])\n",
    "        results.append((precision, cost))\n",
    "    return np.array([r[0] for r in results]), np.array([r[1] for r in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def benchmark_prediction_target(df, tr_size, te_size, samplings=10):\n",
    "    df_res = pd.DataFrame(index=p.basic[:-1])\n",
    "    for i in range(samplings):\n",
    "        df = p.shuffle(df)\n",
    "        dfc = df[:te_size + tr_size].copy()\n",
    "        res_dir = predict_return_quantity_direct(dfc, tr_size, te_size)\n",
    "        res_two = predict_return_quantity_twostep(dfc, tr_size, te_size)\n",
    "        df_res[str(i) + '_precision'] = res_two[0] - res_dir[0]\n",
    "        df_res[str(i) + '_cost'] = res_dir[1] - res_two[1]\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows precision and dmc cost advance when using a two step classification chain. This means, positive numbers are in both cases desirable and underline the positive effect of two chained classifiers. The following result is created using 5 random subsamples with 24000 elements using 4k as training set. Negative number indicate that the single target classifier is stronger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_precision</th>\n",
       "      <th>0_cost</th>\n",
       "      <th>1_precision</th>\n",
       "      <th>1_cost</th>\n",
       "      <th>2_precision</th>\n",
       "      <th>2_cost</th>\n",
       "      <th>3_precision</th>\n",
       "      <th>3_cost</th>\n",
       "      <th>4_precision</th>\n",
       "      <th>4_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;class 'dmc.classifiers.DecisionTree'&gt;</th>\n",
       "      <td>-0.00310</td>\n",
       "      <td>-33</td>\n",
       "      <td>0.00265</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00045</td>\n",
       "      <td>42</td>\n",
       "      <td>0.00575</td>\n",
       "      <td>137</td>\n",
       "      <td>0.00715</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'dmc.classifiers.Forest'&gt;</th>\n",
       "      <td>-0.00185</td>\n",
       "      <td>-20</td>\n",
       "      <td>-0.00020</td>\n",
       "      <td>19</td>\n",
       "      <td>0.00380</td>\n",
       "      <td>91</td>\n",
       "      <td>0.00165</td>\n",
       "      <td>43</td>\n",
       "      <td>-0.00005</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'dmc.classifiers.NaiveBayes'&gt;</th>\n",
       "      <td>0.00110</td>\n",
       "      <td>35</td>\n",
       "      <td>0.00155</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>38</td>\n",
       "      <td>0.00115</td>\n",
       "      <td>31</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'dmc.classifiers.SVM'&gt;</th>\n",
       "      <td>0.00050</td>\n",
       "      <td>27</td>\n",
       "      <td>0.00210</td>\n",
       "      <td>64</td>\n",
       "      <td>0.00130</td>\n",
       "      <td>45</td>\n",
       "      <td>-0.00015</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0_precision  0_cost  1_precision  \\\n",
       "<class 'dmc.classifiers.DecisionTree'>     -0.00310     -33      0.00265   \n",
       "<class 'dmc.classifiers.Forest'>           -0.00185     -20     -0.00020   \n",
       "<class 'dmc.classifiers.NaiveBayes'>        0.00110      35      0.00155   \n",
       "<class 'dmc.classifiers.SVM'>               0.00050      27      0.00210   \n",
       "\n",
       "                                        1_cost  2_precision  2_cost  \\\n",
       "<class 'dmc.classifiers.DecisionTree'>      80      0.00045      42   \n",
       "<class 'dmc.classifiers.Forest'>            19      0.00380      91   \n",
       "<class 'dmc.classifiers.NaiveBayes'>        52      0.00110      38   \n",
       "<class 'dmc.classifiers.SVM'>               64      0.00130      45   \n",
       "\n",
       "                                        3_precision  3_cost  4_precision  \\\n",
       "<class 'dmc.classifiers.DecisionTree'>      0.00575     137      0.00715   \n",
       "<class 'dmc.classifiers.Forest'>            0.00165      43     -0.00005   \n",
       "<class 'dmc.classifiers.NaiveBayes'>        0.00115      31      0.00150   \n",
       "<class 'dmc.classifiers.SVM'>              -0.00015       7      0.00035   \n",
       "\n",
       "                                        4_cost  \n",
       "<class 'dmc.classifiers.DecisionTree'>     168  \n",
       "<class 'dmc.classifiers.Forest'>             9  \n",
       "<class 'dmc.classifiers.NaiveBayes'>        41  \n",
       "<class 'dmc.classifiers.SVM'>               19  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_prediction_target(df, 4000, 20000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
