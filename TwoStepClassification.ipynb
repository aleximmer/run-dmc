{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two step classification benchmark\n",
    "The purpose of this notebook consists in benchmarking two step classification against one step classification. Advantage of a two step approach is that most classifiers (especially SVM) have significantly shorter training times. Thus it should be evaluated how precision behaves in both approaches and the best classifier for predicting the final return quantity should be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import process as p\n",
    "import dmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = p.processed_data()\n",
    "for c in [col for col in df.columns if 'Prob' in col]:\n",
    "    df = df.drop(c, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_return_quantity_direct(df, tr_size, te_size):\n",
    "    results = []\n",
    "    X, Y = dmc.transformation.transform(df, scaler=dmc.normalization.scale_features,\n",
    "                                        binary_target=False)\n",
    "    train = X[:tr_size], Y[:tr_size]\n",
    "    test = X[tr_size:tr_size + te_size], Y[tr_size:tr_size + te_size]\n",
    "    for classifier in p.basic[:-1]:\n",
    "        clf = classifier(train[0], train[1])\n",
    "        res = clf(test[0])\n",
    "        precision = dmc.evaluation.precision(res, test[1])\n",
    "        cost = dmc.evaluation.dmc_cost(res, test[1])\n",
    "        results.append((precision, cost, str(classifier)))\n",
    "    return results\n",
    "        \n",
    "def predict_return_quantity_twostep(df, tr_size, te_size):\n",
    "    results = {\n",
    "        'precision': [],\n",
    "        'cost': []\n",
    "    }\n",
    "    X, Y = dmc.transformation.transform(df, scaler=dmc.normalization.scale_features,\n",
    "                                        binary_target=True)\n",
    "    Y_fin = dmc.transformation.transform_target_vector(df, binary=False)\n",
    "    train = X[:tr_size], Y[:tr_size]\n",
    "    test = X[tr_size:tr_size + te_size], Y[tr_size:tr_size + te_size]\n",
    "    for classifier in p.basic[:-1]:\n",
    "        clf = classifier(train[0], train[1])\n",
    "        res = clf(test[0])\n",
    "        Y_csr, res_csr = csr_matrix(Y).T, csr_matrix(res).T\n",
    "        train_fin = hstack([train[0], Y_csr[:tr_size]]), Y_fin[:tr_size]\n",
    "        test_fin = hstack([test[0], res_csr]), Y_fin[tr_size:tr_size + te_size]\n",
    "        clf_fin = classifier(train_fin[0], train_fin[1])\n",
    "        res_fin = clf_fin(test_fin[0])\n",
    "        precision = dmc.evaluation.precision(res_fin, test_fin[1])\n",
    "        cost = dmc.evaluation.dmc_cost(res_fin, test_fin[1])\n",
    "        results.append((precision, cost, str(classifier)))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def benchmark_prediction_target(df, tr_size, te_size):\n",
    "    df = p.shuffle(df)\n",
    "    dfc = df[:te_size + tr_size].copy()\n",
    "    print(predict_return_quantity_direct(dfc, tr_size, te_size))\n",
    "    print(predict_return_quantity_twostep(dfc, tr_size, te_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.56775, 8681, \"<class 'dmc.classifiers.DecisionTree'>\"), (0.636, 7303, \"<class 'dmc.classifiers.Forest'>\"), (0.6285000000000001, 7452, \"<class 'dmc.classifiers.NaiveBayes'>\"), (0.5862499999999999, 8297, \"<class 'dmc.classifiers.SVM'>\")]\n",
      "[(0.5666, 8668, \"<class 'dmc.classifiers.DecisionTree'>\"), (0.6327499999999999, 7345, \"<class 'dmc.classifiers.Forest'>\"), (0.6304000000000001, 7392, \"<class 'dmc.classifiers.NaiveBayes'>\"), (0.5881000000000001, 8238, \"<class 'dmc.classifiers.SVM'>\")]\n"
     ]
    }
   ],
   "source": [
    "benchmark_prediction_target(df, 5000, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
